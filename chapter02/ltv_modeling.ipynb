{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "# import data processing modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# import model selection modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import data modeling modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin a simple transformation pipeline: one-hot encode all categorical variables, impute median of missing continuous variables, and then standardize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_data['SalePrice']\n",
    "X = training_data.drop(columns=['Id', 'SalePrice'], inplace=False)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('most_common', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "cat_features = list(X.columns[X.dtypes == 'object'])\n",
    "num_features = list(X.columns[X.dtypes != 'object'])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features),\n",
    "    ('missing-indicator', MissingIndicator(error_on_new=False), list(X.columns))\n",
    "])\n",
    "\n",
    "X_piped = full_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(model, data, labels, scoring='neg_mean_squared_error', cv=10):\n",
    "    \"\"\" \n",
    "    Perform cross-validation on model and return average error-rate\n",
    "    \"\"\"\n",
    "    scores = cross_val_score(model, data, labels, scoring=scoring, cv=cv)\n",
    "    return np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(models, data, labels):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on all models in [models] and \n",
    "    return model with best cv score\n",
    "    \"\"\"\n",
    "    model_scores = []\n",
    "    for model in models:\n",
    "        model_scores.append((model, cv(model, data, labels)))\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(model_scores, data=X_piped, y=y):\n",
    "    best_to_worst = sorted(model_scores, key = lambda x: x[1])\n",
    "    best = best_to_worst[0][0]\n",
    "    best_fitted = best.fit(X_piped, y)\n",
    "    return best_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor(), SVR(), MLPRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = best_model(models, X_piped, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       "  115968811883418.5),\n",
       " (DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                        max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        presort=False, random_state=None, splitter='best'),\n",
       "  39253.93435569176),\n",
       " (RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                        max_features='auto', max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False), 28818.185120344144),\n",
       " (SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "      gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "      tol=0.001, verbose=False), 80867.87758888598),\n",
       " (MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "               learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "               n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "               random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "               validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "  185134.48001263308)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = get_best_model(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_leaf_nodes': [10, 100, 1000, None],\n",
       "                                        'n_estimators': [10, 100, 1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'bootstrap': [True, False],\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'max_leaf_nodes': [10, 100, 1000, None]\n",
    "    }\n",
    "\n",
    "\n",
    "rand_forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = RandomizedSearchCV(rand_forest_reg, \n",
    "                                 param_grid, cv=5,\n",
    "                                 scoring='neg_mean_squared_error',\n",
    "                                 return_train_score=True)\n",
    "grid_search.fit(X_piped, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_ids = test_data['Id']\n",
    "test_data.drop(columns=['Id'], inplace=True)\n",
    "test_processed = full_pipeline.transform(test_data)\n",
    "test_predictions = best_model.predict(test_processed)\n",
    "grid_predictions = grid_search.predict(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'id': test_ids, 'SalePrice': test_predictions})\n",
    "predictions.to_csv('submissions.csv',index=False)\n",
    "\n",
    "grid_predictions = pd.DataFrame({'id': test_ids, 'SalePrice': grid_predictions})\n",
    "grid_predictions.to_csv('grid_submissions.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
